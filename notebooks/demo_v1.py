"""
é‡‘èæ•°æ®åˆ†æç®¡é“
================

å°†ç”¨æˆ·éœ€æ±‚ç¿»è¯‘ä¸º AKShare æ•°æ®è·å–é€»è¾‘ï¼Œä½¿ç”¨ TimeCopilot è¿›è¡Œåˆ†æé¢„æµ‹

æ¶æ„:
    ç”¨æˆ·éœ€æ±‚ -> DeepSeek Agent è§£æ -> AKShare è·å–æ•°æ® -> æ•°æ®è½¬æ¢ -> TimeCopilot é¢„æµ‹ -> ç»“æœè¾“å‡º

ä¾èµ–å®‰è£…:
    pip install akshare timecopilot openai pandas matplotlib

ç¯å¢ƒå˜é‡:
    DEEPSEEK_API_KEY: DeepSeek API Key
    OPENAI_API_KEY: OpenAI API Key (TimeCopilot éœ€è¦)
"""

import os
import json
import pandas as pd
from datetime import datetime
from typing import Dict, Any, Optional, Tuple
from dataclasses import dataclass
from pydantic_ai.providers.deepseek import DeepSeekProvider
from pydantic_ai.models.openai import OpenAIChatModel

# ============================================================
# é…ç½®
# ============================================================

AKSHARE_API_DOCS = """
## AKShare å¸¸ç”¨æ•°æ®æ¥å£

### è‚¡ç¥¨æ•°æ®
1. **stock_zh_a_hist** - Aè‚¡å†å²è¡Œæƒ…æ•°æ®
   - å‚æ•°: symbol(è‚¡ç¥¨ä»£ç å¦‚"000001"), period("daily"/"weekly"/"monthly"), 
           start_date("YYYYMMDD"), end_date("YYYYMMDD"), adjust("qfq"/"hfq"/"")
   - è¿”å›: æ—¥æœŸ,å¼€ç›˜,æ”¶ç›˜,æœ€é«˜,æœ€ä½,æˆäº¤é‡,æˆäº¤é¢,æŒ¯å¹…,æ¶¨è·Œå¹…,æ¶¨è·Œé¢,æ¢æ‰‹ç‡

2. **stock_zh_a_spot_em** - Aè‚¡å®æ—¶è¡Œæƒ…
   - å‚æ•°: æ— 
   - è¿”å›: æ‰€æœ‰Aè‚¡å®æ—¶è¡Œæƒ…æ•°æ®

### æŒ‡æ•°æ•°æ®
3. **stock_zh_index_daily_em** - è‚¡ç¥¨æŒ‡æ•°å†å²æ•°æ®
   - å‚æ•°: symbol(æŒ‡æ•°ä»£ç å¦‚"sh000001"ä¸Šè¯æŒ‡æ•°, "sz399001"æ·±è¯æˆæŒ‡)
   - è¿”å›: date,open,close,high,low,volume,amount

4. **index_zh_a_hist** - æŒ‡æ•°å†å²è¡Œæƒ…(å¸¦æ—¥æœŸèŒƒå›´)
   - å‚æ•°: symbol, period, start_date, end_date

### åŸºé‡‘æ•°æ®
5. **fund_etf_hist_em** - ETFåŸºé‡‘å†å²æ•°æ®
   - å‚æ•°: symbol(ETFä»£ç ), period, start_date, end_date, adjust

### å¸¸ç”¨è‚¡ç¥¨ä»£ç ç¤ºä¾‹
- å¹³å®‰é“¶è¡Œ: 000001
- è´µå·èŒ…å°: 600519
- æ¯”äºšè¿ª: 002594
- å®å¾·æ—¶ä»£: 300750

### å¸¸ç”¨æŒ‡æ•°ä»£ç 
- ä¸Šè¯æŒ‡æ•°: sh000001 æˆ– 000001
- æ·±è¯æˆæŒ‡: sz399001 æˆ– 399001
- åˆ›ä¸šæ¿æŒ‡: sz399006 æˆ– 399006
- æ²ªæ·±300: sh000300 æˆ– 000300
"""


# ============================================================
# æ•°æ®ç±»
# ============================================================

@dataclass
class PipelineResult:
    """ç®¡é“æ‰§è¡Œç»“æœ"""
    config: Dict[str, Any]
    raw_data: pd.DataFrame
    transformed_data: pd.DataFrame
    forecast_df: pd.DataFrame
    forecast_values: Dict[str, Any]
    summary: str
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "config": self.config,
            "forecast_values": self.forecast_values,
            "summary": self.summary,
            "forecast_df": self.forecast_df.to_dict(orient="records") if self.forecast_df is not None else []
        }


# ============================================================
# Agent - éœ€æ±‚è§£æå™¨
# ============================================================

class DataRequestAgent:
    """ä½¿ç”¨ DeepSeek API å°†ç”¨æˆ·è‡ªç„¶è¯­è¨€éœ€æ±‚è½¬æ¢ä¸º AKShare è°ƒç”¨"""
    
    def __init__(self, api_key: str):
        from openai import OpenAI
        self.client = OpenAI(
            api_key=api_key,
            base_url="https://api.deepseek.com"
        )
        self.model = "deepseek-chat"
    
    def parse_request(self, user_query: str) -> Dict[str, Any]:
        """è§£æç”¨æˆ·éœ€æ±‚ï¼Œè¿”å›æ•°æ®è·å–é…ç½®"""
        
        system_prompt = f"""
ä½ æ˜¯ä¸€ä¸ªé‡‘èæ•°æ®åˆ†æåŠ©æ‰‹ã€‚ä½ çš„ä»»åŠ¡æ˜¯å°†ç”¨æˆ·çš„è‡ªç„¶è¯­è¨€éœ€æ±‚è½¬æ¢ä¸º AKShare æ•°æ®è·å–é…ç½®ã€‚

{AKSHARE_API_DOCS}

è¯·æ ¹æ®ç”¨æˆ·éœ€æ±‚ï¼Œè¿”å›ä¸€ä¸ª JSON æ ¼å¼çš„é…ç½®ï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š
1. api_function: AKShare å‡½æ•°å
2. params: å‡½æ•°å‚æ•°å­—å…¸
3. data_type: æ•°æ®ç±»å‹ (stock/index/fund/futures/macro)
4. analysis_type: åˆ†æç±»å‹ (forecasté¢„æµ‹/analysisåˆ†æ)
5. forecast_horizon: é¢„æµ‹å‘¨æœŸ(å¤©æ•°)ï¼Œå¦‚æœæ˜¯é¢„æµ‹ä»»åŠ¡
6. target_column: ç›®æ ‡åˆ—åï¼ˆé€šå¸¸æ˜¯"æ”¶ç›˜"æˆ–"close"ï¼‰
7. user_question: ç”¨æˆ·åŸå§‹é—®é¢˜çš„æ ¸å¿ƒè¯‰æ±‚

æ³¨æ„ï¼š
- å¦‚æœç”¨æˆ·æ²¡æœ‰æŒ‡å®šæ—¥æœŸèŒƒå›´ï¼Œé»˜è®¤è·å–æœ€è¿‘1å¹´çš„æ•°æ®
- æ—¥æœŸæ ¼å¼ä¸º YYYYMMDD
- åªè¿”å› JSONï¼Œä¸è¦å…¶ä»–è§£é‡Š

ä»Šå¤©æ—¥æœŸ: {datetime.now().strftime('%Y-%m-%d')}
"""
        
        response = self.client.chat.completions.create(
            model=self.model,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_query}
            ],
            temperature=0.1,
            response_format={"type": "json_object"}
        )
        
        return json.loads(response.choices[0].message.content)
    
    def generate_summary(self, forecast_result: Dict, original_query: str) -> str:
        """æ ¹æ®é¢„æµ‹ç»“æœç”Ÿæˆè‡ªç„¶è¯­è¨€æ€»ç»“"""
        
        prompt = f"""
ç”¨æˆ·åŸå§‹é—®é¢˜: {original_query}

é¢„æµ‹ç»“æœ:
- é€‰ç”¨æ¨¡å‹: {forecast_result.get('selected_model', 'N/A')}
- æ¨¡å‹é€‰æ‹©åŸå› : {forecast_result.get('reason_for_selection', 'N/A')}
- æ—¶åºç‰¹å¾åˆ†æ: {forecast_result.get('tsfeatures_analysis', 'N/A')}
- é¢„æµ‹åˆ†æ: {forecast_result.get('forecast_analysis', 'N/A')}
- é¢„æµ‹å€¼: {forecast_result.get('forecast', [])[:10]}... (å‰10ä¸ª)

è¯·ç”¨ä¸­æ–‡ä¸ºç”¨æˆ·ç”Ÿæˆä¸€ä¸ªç®€æ´ä¸“ä¸šçš„åˆ†ææŠ¥å‘Šï¼ŒåŒ…å«:
1. æ•°æ®ç‰¹å¾æ¦‚è¿°
2. æ¨¡å‹é€‰æ‹©è¯´æ˜
3. é¢„æµ‹è¶‹åŠ¿æ€»ç»“
4. æŠ•èµ„å»ºè®®ï¼ˆé£é™©æç¤ºï¼‰

æ³¨æ„: ä¿æŒå®¢è§‚ï¼Œæ·»åŠ å¿…è¦çš„é£é™©æç¤ºã€‚
"""
        
        response = self.client.chat.completions.create(
            model=self.model,
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3
        )
        
        return response.choices[0].message.content


# ============================================================
# æ•°æ®è·å–å±‚
# ============================================================

class DataFetcher:
    """ä½¿ç”¨ AKShare è·å–é‡‘èæ•°æ®"""
    
    @staticmethod
    def fetch_data(config: Dict[str, Any]) -> pd.DataFrame:
        """æ ¹æ®é…ç½®è·å–æ•°æ®"""
        import akshare as ak
        
        api_mapping = {
            "stock_zh_a_hist": ak.stock_zh_a_hist,
            "stock_zh_a_spot_em": ak.stock_zh_a_spot_em,
            "stock_zh_index_daily_em": ak.stock_zh_index_daily_em,
            "index_zh_a_hist": ak.index_zh_a_hist,
            "fund_etf_hist_em": ak.fund_etf_hist_em,
        }
        
        api_function = config.get("api_function")
        params = config.get("params", {})
        
        if api_function not in api_mapping:
            raise ValueError(f"ä¸æ”¯æŒçš„ API å‡½æ•°: {api_function}")
        
        func = api_mapping[api_function]
        df = func(**params)
        
        print(f"âœ… æˆåŠŸè·å–æ•°æ®ï¼Œå…± {len(df)} æ¡è®°å½•")
        return df


# ============================================================
# æ•°æ®è½¬æ¢å±‚
# ============================================================

class DataTransformer:
    """å°† AKShare æ•°æ®è½¬æ¢ä¸º TimeCopilot æ‰€éœ€æ ¼å¼"""
    
    @staticmethod
    def transform_for_timecopilot(
        df: pd.DataFrame, 
        config: Dict[str, Any]
    ) -> pd.DataFrame:
        """
        è½¬æ¢æ•°æ®æ ¼å¼
        
        TimeCopilot è¦æ±‚çš„æ ¼å¼:
        - unique_id: æ—¶åºå”¯ä¸€æ ‡è¯† (string)
        - ds: æ—¥æœŸåˆ— (datetime)
        - y: ç›®æ ‡å˜é‡ (float)
        """
        
        df_copy = df.copy()
        
        # æ£€æµ‹æ—¥æœŸåˆ—
        date_columns = ["æ—¥æœŸ", "date", "Date", "æ—¶é—´", "time"]
        date_col = None
        for col in date_columns:
            if col in df_copy.columns:
                date_col = col
                break
        
        if date_col is None:
            if isinstance(df_copy.index, pd.DatetimeIndex):
                df_copy = df_copy.reset_index()
                date_col = df_copy.columns[0]
            else:
                raise ValueError("æœªæ‰¾åˆ°æ—¥æœŸåˆ—")
        
        # æ£€æµ‹ç›®æ ‡åˆ—
        target_col = config.get("target_column", "æ”¶ç›˜")
        target_columns = [target_col, "close", "Close", "æ”¶ç›˜", "æ”¶ç›˜ä»·"]
        y_col = None
        for col in target_columns:
            if col in df_copy.columns:
                y_col = col
                break
        
        if y_col is None:
            numeric_cols = df_copy.select_dtypes(include=['float64', 'int64']).columns
            if len(numeric_cols) > 0:
                y_col = numeric_cols[0]
            else:
                raise ValueError("æœªæ‰¾åˆ°ç›®æ ‡æ•°å€¼åˆ—")
        
        # ç”Ÿæˆ unique_id
        symbol = config.get("params", {}).get("symbol", "unknown")
        
        # æ„å»º TimeCopilot æ ¼å¼
        result = pd.DataFrame({
            "unique_id": symbol,
            "ds": pd.to_datetime(df_copy[date_col]),
            "y": df_copy[y_col].astype(float)
        })
        
        result = result.sort_values("ds").drop_duplicates(subset=["ds"]).reset_index(drop=True)
        
        print(f"âœ… æ•°æ®è½¬æ¢å®Œæˆ: {len(result)} æ¡è®°å½•")
        print(f"   æ—¥æœŸèŒƒå›´: {result['ds'].min()} ~ {result['ds'].max()}")
        
        return result


# ============================================================
# åˆ†æ/é¢„æµ‹å±‚
# ============================================================

class TimeSeriesAnalyzer:
    """ä½¿ç”¨ TimeCopilot è¿›è¡Œæ—¶åºåˆ†æå’Œé¢„æµ‹"""
    
    def __init__(self, llm_model: str = "openai:gpt-4o-mini"):
        from timecopilot import TimeCopilot
        self.tc = TimeCopilot(llm=llm_model, retries=3)
    
    def forecast(
        self, 
        df: pd.DataFrame, 
        horizon: int = 30,
        freq: str = "D",
        query: Optional[str] = None
    ) -> Tuple[Any, pd.DataFrame]:
        """æ‰§è¡Œæ—¶åºé¢„æµ‹"""
        
        print(f"ğŸ”® å¼€å§‹é¢„æµ‹ï¼Œé¢„æµ‹å‘¨æœŸ: {horizon} {freq}")
        
        result = self.tc.forecast(
            df=df,
            freq=freq,
            h=horizon,
            query=query
        )
        
        return result.output, result.fcst_df
    
    @staticmethod
    def extract_forecast_values(result_output) -> Dict[str, Any]:
        """æå–é¢„æµ‹ç»“æœçš„å…³é”®ä¿¡æ¯"""
        return {
            "selected_model": getattr(result_output, 'selected_model', 'N/A'),
            "model_details": getattr(result_output, 'model_details', 'N/A'),
            "tsfeatures_analysis": getattr(result_output, 'tsfeatures_analysis', 'N/A'),
            "forecast_analysis": getattr(result_output, 'forecast_analysis', 'N/A'),
            "reason_for_selection": getattr(result_output, 'reason_for_selection', 'N/A'),
            "forecast": getattr(result_output, 'forecast', []),
            "is_better_than_seasonal_naive": getattr(result_output, 'is_better_than_seasonal_naive', None),
            "cross_validation_results": getattr(result_output, 'cross_validation_results', []),
            "user_query_response": getattr(result_output, 'user_query_response', None)
        }


# ============================================================
# å®Œæ•´ç®¡é“
# ============================================================

class FinancialDataPipeline:
    """
    é‡‘èæ•°æ®åˆ†æç®¡é“
    
    å®Œæ•´æµç¨‹:
    ç”¨æˆ·éœ€æ±‚ -> Agentè§£æ -> æ•°æ®è·å– -> æ•°æ®è½¬æ¢ -> æ—¶åºåˆ†æ -> ç»“æœè¾“å‡º
    """
    
    def __init__(self, deepseek_api_key: str, openai_api_key: str):
   
        self.agent = DataRequestAgent(deepseek_api_key)
        self.llm_model = OpenAIChatModel(
            'deepseek-chat',
            provider=DeepSeekProvider(api_key=deepseek_api_key),
        )
        self.analyzer = TimeSeriesAnalyzer(llm_model=self.llm_model)
        
        # ç¡®ä¿ç¯å¢ƒå˜é‡è®¾ç½®
        # os.environ["OPENAI_API_KEY"] = openai_api_key
    
    def run(self, user_query: str) -> PipelineResult:
        """æ‰§è¡Œå®Œæ•´çš„åˆ†æç®¡é“"""
        
        print("="*60)
        print(f"ğŸ“ ç”¨æˆ·éœ€æ±‚: {user_query}")
        print("="*60)
        
        # Step 1: Agent è§£æéœ€æ±‚
        print("\nğŸ¤– Step 1: è§£æç”¨æˆ·éœ€æ±‚...")
        config = self.agent.parse_request(user_query)
        print(f"   APIå‡½æ•°: {config.get('api_function')}")
        print(f"   å‚æ•°: {config.get('params')}")
        
        # Step 2: è·å–æ•°æ®
        print("\nğŸ“Š Step 2: è·å–æ•°æ®...")
        raw_data = DataFetcher.fetch_data(config)
        print(raw_data.head())
        
        # Step 3: è½¬æ¢æ•°æ®
        print("\nğŸ”„ Step 3: è½¬æ¢æ•°æ®æ ¼å¼...")
        transformed_data = DataTransformer.transform_for_timecopilot(raw_data, config)
        print(transformed_data.head())
        
        # Step 4: æ—¶åºåˆ†æ/é¢„æµ‹
        print("\nğŸ”® Step 4: æ‰§è¡Œæ—¶åºé¢„æµ‹...")
        forecast_horizon = config.get("forecast_horizon", 30)
        forecast_query = config.get("user_question", user_query)
        
        forecast_output, forecast_df = self.analyzer.forecast(
            df=transformed_data,
            horizon=forecast_horizon,
            freq="D",
            query=forecast_query
        )
        
        forecast_values = self.analyzer.extract_forecast_values(forecast_output)
        
        # Step 5: ç”Ÿæˆæ€»ç»“
        print("\nğŸ“‹ Step 5: ç”Ÿæˆåˆ†ææŠ¥å‘Š...")
        summary = self.agent.generate_summary(forecast_values, user_query)
        
        # æ„å»ºç»“æœ
        result = PipelineResult(
            config=config,
            raw_data=raw_data,
            transformed_data=transformed_data,
            forecast_df=forecast_df,
            forecast_values=forecast_values,
            summary=summary
        )
        
        print("\n" + "="*60)
        print("ğŸ“Š åˆ†ææŠ¥å‘Š")
        print("="*60)
        print(summary)
        
        return result


# ============================================================
# ä¾¿æ·å‡½æ•°
# ============================================================

def analyze(
    query: str, 
    deepseek_key: str = None, 
    openai_key: str = None
) -> PipelineResult:
    """
    å¿«é€Ÿåˆ†æå‡½æ•°
    
    Args:
        query: è‡ªç„¶è¯­è¨€åˆ†æéœ€æ±‚
        deepseek_key: DeepSeek API Key
        openai_key: OpenAI API Key
        
    Returns:
        PipelineResult å¯¹è±¡
        
    Example:
        result = analyze("åˆ†æè´µå·èŒ…å°æœ€è¿‘çš„èµ°åŠ¿å¹¶é¢„æµ‹æœªæ¥30å¤©")
        print(result.summary)
        print(result.forecast_df)
    """
    deepseek_key = deepseek_key or os.environ.get("DEEPSEEK_API_KEY")
    openai_key = openai_key or os.environ.get("OPENAI_API_KEY")
    
    if not deepseek_key:
        raise ValueError("è¯·è®¾ç½® DEEPSEEK_API_KEY å’Œ OPENAI_API_KEY ç¯å¢ƒå˜é‡")
    
    pipeline = FinancialDataPipeline(deepseek_key, openai_key)
    return pipeline.run(query)


# ============================================================
# CLI å…¥å£
# ============================================================

if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1:
        query = " ".join(sys.argv[1:])
    else:
        query = input("è¯·è¾“å…¥æ‚¨çš„åˆ†æéœ€æ±‚: ")
    
    try:
        result = analyze(query)
        
        print("\n" + "="*60)
        print("é¢„æµ‹æ•°å€¼ (å‰10ä¸ª):")
        print("="*60)
        if result.forecast_df is not None:
            print(result.forecast_df.head(10))
            
    except Exception as e:
        print(f"âŒ æ‰§è¡Œå¤±è´¥: {e}")
        raise