"""
é‡‘èæ•°æ®å¯¹è¯å¼åˆ†æ Agent
========================

å®Œæ•´ç®¡é“: è‡ªç„¶è¯­è¨€ â†’ AKShareæ•°æ® â†’ æ—¶åºé¢„æµ‹ â†’ åˆ†ææŠ¥å‘Š

ä¾èµ–:
    pip install prophet xgboost pydantic-ai akshare pandas matplotlib openai

ç¯å¢ƒå˜é‡:
    DEEPSEEK_API_KEY: DeepSeek API Key
"""

import os
import json
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, Any, Optional, List
from dataclasses import dataclass
from pydantic import BaseModel, Field, ConfigDict
from openai import OpenAI

# ============================================================
# é…ç½®
# ============================================================

AKSHARE_API_DOCS = """
## AKShare æ•°æ®æ¥å£

### è‚¡ç¥¨æ•°æ®
- stock_zh_a_hist: Aè‚¡å†å²è¡Œæƒ…
  å‚æ•°: symbol(ä»£ç ), period(daily/weekly/monthly), start_date, end_date, adjust(qfq/hfq/"")
  
### æŒ‡æ•°æ•°æ®  
- stock_zh_index_daily_em: æŒ‡æ•°å†å²æ•°æ®
  å‚æ•°: symbol (sh000001=ä¸Šè¯, sz399001=æ·±è¯, sz399006=åˆ›ä¸šæ¿)

### å¸¸ç”¨ä»£ç 
- å¹³å®‰é“¶è¡Œ: 000001, è´µå·èŒ…å°: 600519, æ¯”äºšè¿ª: 002594
- ä¸Šè¯æŒ‡æ•°: sh000001, æ²ªæ·±300: sh000300
"""


# ============================================================
# æ•°æ®æ¨¡å‹
# ============================================================

class DataConfig(BaseModel):
    """æ•°æ®è·å–é…ç½®"""
    api_function: str
    params: Dict[str, Any]
    data_type: str  # stock / index / fund
    target_column: str = "æ”¶ç›˜"

class AnalysisConfig(BaseModel):
    """åˆ†æé…ç½®"""
    forecast_horizon: int = 30
    model: str = "prophet"
    user_question: str = ""

class PipelineResult(BaseModel):
    """ç®¡é“ç»“æœ"""
    model_config = ConfigDict(arbitrary_types_allowed=True)
    
    data_config: Dict[str, Any]
    features: Dict[str, Any]
    forecast: List[Dict[str, Any]]
    metrics: Dict[str, float]
    analysis: str


# ============================================================
# ç¬¬ä¸€å±‚: è‡ªç„¶è¯­è¨€è§£æ Agent
# ============================================================

class NLPAgent:
    """è‡ªç„¶è¯­è¨€è§£æ â†’ AKShare é…ç½®"""
    
    def __init__(self, api_key: str):
        self.client = OpenAI(
            api_key=api_key,
            base_url="https://api.deepseek.com"
        )
    
    def parse(self, user_query: str) -> Dict[str, Any]:
        """è§£æç”¨æˆ·è¾“å…¥ï¼Œè¿”å›æ•°æ®é…ç½®å’Œåˆ†æé…ç½®"""
        
        today = datetime.now()
        one_year_ago = today - timedelta(days=365)
        
        system_prompt = f"""ä½ æ˜¯é‡‘èæ•°æ®åŠ©æ‰‹ã€‚å°†ç”¨æˆ·éœ€æ±‚è½¬æ¢ä¸º AKShare æ•°æ®è·å–é…ç½®ã€‚

{AKSHARE_API_DOCS}

è¿”å› JSON æ ¼å¼:
{{
    "data_config": {{
        "api_function": "stock_zh_a_hist",
        "params": {{"symbol": "000001", "period": "daily", "start_date": "YYYYMMDD", "end_date": "YYYYMMDD", "adjust": ""}},
        "data_type": "stock",
        "target_column": "æ”¶ç›˜"
    }},
    "analysis_config": {{
        "forecast_horizon": 30,
        "model": "prophet",
        "user_question": "ç”¨æˆ·é—®é¢˜çš„æ ¸å¿ƒ"
    }}
}}

æ³¨æ„:
- é»˜è®¤è·å–æœ€è¿‘1å¹´æ•°æ®
- æ—¥æœŸæ ¼å¼ YYYYMMDD
- ä»Šå¤©: {today.strftime('%Y-%m-%d')}
- ä¸€å¹´å‰: {one_year_ago.strftime('%Y-%m-%d')}
- model å­—æ®µå›ºå®šè¿”å› "prophet"ï¼ˆå®é™…æ¨¡å‹é€‰æ‹©ç”±å¤–éƒ¨å‚æ•°æ§åˆ¶ï¼‰
- åªè¿”å› JSON
"""
        
        response = self.client.chat.completions.create(
            model="deepseek-chat",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_query}
            ],
            temperature=0.1,
            response_format={"type": "json_object"}
        )
        
        return json.loads(response.choices[0].message.content)


# ============================================================
# ç¬¬äºŒå±‚: æ•°æ®è·å–
# ============================================================

class DataFetcher:
    """AKShare æ•°æ®è·å–"""
    
    @staticmethod
    def fetch(config: Dict[str, Any]) -> pd.DataFrame:
        """æ ¹æ®é…ç½®è·å–æ•°æ®"""
        import akshare as ak
        
        api_map = {
            "stock_zh_a_hist": ak.stock_zh_a_hist,
            "stock_zh_index_daily_em": ak.stock_zh_index_daily_em,
            "fund_etf_hist_em": ak.fund_etf_hist_em,
        }
        
        func_name = config["api_function"]
        params = config["params"]
        
        if func_name not in api_map:
            raise ValueError(f"ä¸æ”¯æŒ: {func_name}")
        
        df = api_map[func_name](**params)
        print(f"âœ… è·å–æ•°æ®: {len(df)} æ¡")
        return df
    
    @staticmethod
    def prepare(df: pd.DataFrame, config: Dict[str, Any]) -> pd.DataFrame:
        """è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼ (ds, y)"""
        
        # æ£€æµ‹æ—¥æœŸåˆ—
        date_col = None
        for col in ["æ—¥æœŸ", "date", "Date"]:
            if col in df.columns:
                date_col = col
                break
        
        # æ£€æµ‹å€¼åˆ—
        target = config.get("target_column", "æ”¶ç›˜")
        value_col = None
        for col in [target, "close", "Close", "æ”¶ç›˜"]:
            if col in df.columns:
                value_col = col
                break
        
        if not date_col or not value_col:
            raise ValueError(f"æ— æ³•è¯†åˆ«åˆ—: {list(df.columns)}")
        
        result = pd.DataFrame({
            "ds": pd.to_datetime(df[date_col]),
            "y": df[value_col].astype(float)
        }).sort_values("ds").drop_duplicates("ds").reset_index(drop=True)
        
        print(f"âœ… æ•°æ®å‡†å¤‡: {len(result)} æ¡, {result['ds'].min().date()} ~ {result['ds'].max().date()}")
        return result


# ============================================================
# ç¬¬ä¸‰å±‚: æ—¶åºåˆ†æ
# ============================================================

class TimeSeriesAnalyzer:
    """æ—¶åºåˆ†æ + é¢„æµ‹"""
    
    @staticmethod
    def analyze_features(df: pd.DataFrame) -> Dict[str, Any]:
        """åˆ†ææ—¶åºç‰¹å¾"""
        y = df["y"].values
        
        # è¶‹åŠ¿
        mid = len(y) // 2
        first_mean, second_mean = np.mean(y[:mid]), np.mean(y[mid:])
        if second_mean > first_mean * 1.05:
            trend = "ä¸Šå‡"
        elif second_mean < first_mean * 0.95:
            trend = "ä¸‹é™"
        else:
            trend = "å¹³ç¨³"
        
        # æ³¢åŠ¨æ€§
        cv = np.std(y) / np.mean(y) if np.mean(y) != 0 else 0
        volatility = "é«˜" if cv > 0.3 else ("ä¸­" if cv > 0.1 else "ä½")
        
        # ç»Ÿè®¡
        return {
            "trend": trend,
            "volatility": volatility,
            "mean": round(float(np.mean(y)), 2),
            "std": round(float(np.std(y)), 2),
            "min": round(float(np.min(y)), 2),
            "max": round(float(np.max(y)), 2),
            "latest": round(float(y[-1]), 2),
            "data_points": len(y),
            "date_range": f"{df['ds'].min().date()} ~ {df['ds'].max().date()}"
        }
    
    @staticmethod
    def forecast_prophet(df: pd.DataFrame, horizon: int = 30) -> Dict[str, Any]:
        """Prophet é¢„æµ‹"""
        from prophet import Prophet
        
        model = Prophet(
            daily_seasonality=False,
            weekly_seasonality=True,
            yearly_seasonality=True,
            changepoint_prior_scale=0.05,
        )
        model.fit(df[["ds", "y"]])
        
        future = model.make_future_dataframe(periods=horizon, freq="D")
        forecast = model.predict(future)
        
        # æå–é¢„æµ‹
        pred = forecast.tail(horizon)
        forecast_values = [
            {
                "date": row["ds"].strftime("%Y-%m-%d"),
                "value": round(row["yhat"], 2),
                "lower": round(row["yhat_lower"], 2),
                "upper": round(row["yhat_upper"], 2),
            }
            for _, row in pred.iterrows()
        ]
        
        # è®¡ç®— MAE
        train_pred = forecast.head(len(df))
        mae = np.mean(np.abs(df["y"].values - train_pred["yhat"].values))
        
        return {
            "forecast": forecast_values,
            "metrics": {"mae": round(mae, 4)},
            "model": "prophet"
        }
    
    @staticmethod
    def _create_features(df: pd.DataFrame, max_lag: int = 30) -> pd.DataFrame:
        """åˆ›å»ºæ—¶åºç‰¹å¾ç”¨äº XGBoost"""
        feature_df = df.copy()
        
        # æ»åç‰¹å¾
        for lag in [1, 7, 14, 30]:
            if lag <= max_lag and lag < len(feature_df):
                feature_df[f"lag_{lag}"] = feature_df["y"].shift(lag)
        
        # ç§»åŠ¨å¹³å‡
        for window in [7, 14, 30]:
            if window < len(feature_df):
                feature_df[f"ma_{window}"] = feature_df["y"].rolling(window=window, min_periods=1).mean()
                feature_df[f"std_{window}"] = feature_df["y"].rolling(window=window, min_periods=1).std()
        
        # æ—¶é—´ç‰¹å¾
        feature_df["day_of_week"] = feature_df["ds"].dt.dayofweek
        feature_df["day_of_month"] = feature_df["ds"].dt.day
        feature_df["month"] = feature_df["ds"].dt.month
        feature_df["quarter"] = feature_df["ds"].dt.quarter
        
        # è¶‹åŠ¿ç‰¹å¾
        feature_df["trend"] = np.arange(len(feature_df))
        
        # å¡«å…… NaNï¼ˆç”±æ»åå’Œç§»åŠ¨å¹³å‡äº§ç”Ÿï¼‰
        feature_df = feature_df.bfill().fillna(0)
        
        return feature_df
    
    @staticmethod
    def forecast_xgboost(df: pd.DataFrame, horizon: int = 30) -> Dict[str, Any]:
        """XGBoost é¢„æµ‹"""
        try:
            import xgboost as xgb
        except ImportError:
            raise ImportError("è¯·å®‰è£… xgboost: pip install xgboost")
        
        # æ£€æŸ¥æ•°æ®é‡
        if len(df) < 60:
            raise ValueError(f"XGBoost éœ€è¦è‡³å°‘60æ¡å†å²æ•°æ®ï¼Œå½“å‰åªæœ‰ {len(df)} æ¡")
        
        # åˆ›å»ºç‰¹å¾
        feature_df = TimeSeriesAnalyzer._create_features(df, max_lag=min(30, len(df) // 2))
        
        # å‡†å¤‡è®­ç»ƒæ•°æ®
        feature_cols = [col for col in feature_df.columns if col not in ["ds", "y"]]
        X = feature_df[feature_cols].values
        y = feature_df["y"].values
        
        # åˆ’åˆ†è®­ç»ƒé›†ï¼ˆä½¿ç”¨æœ€å20%ä½œä¸ºéªŒè¯é›†ï¼‰
        split_idx = int(len(X) * 0.8)
        X_train, X_val = X[:split_idx], X[split_idx:]
        y_train, y_val = y[:split_idx], y[split_idx:]
        
        # è®­ç»ƒæ¨¡å‹
        model = xgb.XGBRegressor(
            n_estimators=100,
            max_depth=5,
            learning_rate=0.1,
            subsample=0.8,
            colsample_bytree=0.8,
            random_state=42,
            n_jobs=-1
        )
        # å…¼å®¹ä¸åŒç‰ˆæœ¬çš„ XGBoost
        # XGBoost 2.0+ ä½¿ç”¨ callbacksï¼Œæ—§ç‰ˆæœ¬ä½¿ç”¨ early_stopping_rounds
        try:
            # å°è¯•æ–°ç‰ˆæœ¬æ–¹å¼ (XGBoost 2.0+)
            try:
                early_stop = xgb.callback.EarlyStopping(rounds=10, save_best=True)
                model.fit(
                    X_train, y_train,
                    eval_set=[(X_val, y_val)],
                    callbacks=[early_stop],
                    verbose=False
                )
            except (AttributeError, TypeError):
                # å¦‚æœ callback æ–¹å¼å¤±è´¥ï¼Œå°è¯•æ—§ç‰ˆæœ¬æ–¹å¼
                model.fit(
                    X_train, y_train,
                    eval_set=[(X_val, y_val)],
                    early_stopping_rounds=10,
                    verbose=False
                )
        except TypeError:
            # å¦‚æœä¸¤ç§æ–¹å¼éƒ½å¤±è´¥ï¼Œä¸ä½¿ç”¨ early stopping
            model.fit(
                X_train, y_train,
                eval_set=[(X_val, y_val)],
                verbose=False
            )
        
        # åœ¨è®­ç»ƒé›†ä¸Šé¢„æµ‹ä»¥è®¡ç®—æ®‹å·®
        train_pred = model.predict(X)
        residuals = y - train_pred
        std_error = np.std(residuals)
        
        # é€’å½’é¢„æµ‹æœªæ¥å€¼
        forecast_values = []
        last_features = feature_df.iloc[-1].copy()
        last_date = df["ds"].iloc[-1]
        last_values = df["y"].values[-30:].tolist()  # ä¿å­˜æœ€è¿‘30ä¸ªå€¼ç”¨äºç‰¹å¾è®¡ç®—
        
        for i in range(horizon):
            # åˆ›å»ºæœªæ¥æ—¥æœŸ
            future_date = last_date + timedelta(days=i + 1)
            
            # å‡†å¤‡ç‰¹å¾
            future_features = pd.Series(index=feature_df.columns, dtype=float)
            
            # æ»åç‰¹å¾ï¼ˆä½¿ç”¨é¢„æµ‹å€¼æˆ–å†å²å€¼ï¼‰
            if i == 0:
                future_features["lag_1"] = last_features["y"]
            else:
                future_features["lag_1"] = forecast_values[-1]["value"]
            
            for lag in [7, 14, 30]:
                lag_col = f"lag_{lag}"
                if lag_col in feature_cols:
                    if i + 1 >= lag:
                        if i + 1 - lag < len(forecast_values):
                            future_features[lag_col] = forecast_values[i + 1 - lag]["value"]
                        else:
                            idx = len(last_values) - (lag - (i + 1))
                            future_features[lag_col] = last_values[idx] if idx >= 0 else last_values[0]
                    else:
                        idx = len(last_values) - (lag - i - 1)
                        future_features[lag_col] = last_values[idx] if idx >= 0 else last_values[0]
            
            # ç§»åŠ¨å¹³å‡ï¼ˆä½¿ç”¨å†å²å€¼å’Œé¢„æµ‹å€¼ï¼‰
            all_values = last_values + [f["value"] for f in forecast_values]
            for window in [7, 14, 30]:
                ma_col = f"ma_{window}"
                std_col = f"std_{window}"
                if ma_col in feature_cols:
                    window_values = all_values[-window:] if len(all_values) >= window else all_values
                    future_features[ma_col] = np.mean(window_values)
                    future_features[std_col] = np.std(window_values) if len(window_values) > 1 else 0
            
            # æ—¶é—´ç‰¹å¾
            future_features["day_of_week"] = future_date.dayofweek
            future_features["day_of_month"] = future_date.day
            future_features["month"] = future_date.month
            future_features["quarter"] = future_date.quarter
            
            # è¶‹åŠ¿ç‰¹å¾
            future_features["trend"] = len(df) + i + 1
            
            # å¡«å……ç¼ºå¤±å€¼
            for col in feature_cols:
                if pd.isna(future_features[col]):
                    future_features[col] = feature_df[col].iloc[-1] if col in feature_df.columns else 0
            
            # é¢„æµ‹
            X_future = future_features[feature_cols].values.reshape(1, -1)
            pred_value = model.predict(X_future)[0]
            
            # è®¡ç®—ç½®ä¿¡åŒºé—´ï¼ˆä½¿ç”¨å†å²æ®‹å·®çš„æ ‡å‡†å·®ï¼‰
            lower = pred_value - 1.96 * std_error
            upper = pred_value + 1.96 * std_error
            
            forecast_values.append({
                "date": future_date.strftime("%Y-%m-%d"),
                "value": round(float(pred_value), 2),
                "lower": round(float(lower), 2),
                "upper": round(float(upper), 2),
            })
        
        # è®¡ç®—éªŒè¯é›† MAE
        val_pred = model.predict(X_val)
        mae = np.mean(np.abs(y_val - val_pred))
        rmse = np.sqrt(np.mean((y_val - val_pred) ** 2))
        
        return {
            "forecast": forecast_values,
            "metrics": {
                "mae": round(float(mae), 4),
                "rmse": round(float(rmse), 4)
            },
            "model": "xgboost"
        }


# ============================================================
# ç¬¬å››å±‚: æŠ¥å‘Šç”Ÿæˆ
# ============================================================

class ReportGenerator:
    """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
    
    def __init__(self, api_key: str):
        self.client = OpenAI(
            api_key=api_key,
            base_url="https://api.deepseek.com"
        )
    
    def generate(
        self, 
        user_question: str,
        features: Dict[str, Any],
        forecast_result: Dict[str, Any]
    ) -> str:
        """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
        
        forecast_preview = forecast_result["forecast"][:7]  # å‰7å¤©
        
        prompt = f"""ç”¨æˆ·é—®é¢˜: {user_question}

æ•°æ®ç‰¹å¾:
- è¶‹åŠ¿: {features['trend']}
- æ³¢åŠ¨æ€§: {features['volatility']}
- å‡å€¼: {features['mean']}, æœ€æ–°: {features['latest']}
- åŒºé—´: [{features['min']}, {features['max']}]
- æ•°æ®é‡: {features['data_points']} å¤©
- æ—¶é—´: {features['date_range']}

é¢„æµ‹ç»“æœ ({forecast_result['model']}):
- é¢„æµ‹å¤©æ•°: {len(forecast_result['forecast'])}
- æœªæ¥7å¤©: {json.dumps(forecast_preview, ensure_ascii=False)}
- MAE: {forecast_result['metrics'].get('mae', 'N/A')}

è¯·ç”Ÿæˆç®€æ´çš„ä¸­æ–‡åˆ†ææŠ¥å‘Š:
1. å†å²èµ°åŠ¿åˆ†æ (2å¥)
2. é¢„æµ‹è¶‹åŠ¿è§£è¯» (2å¥)  
3. æŠ•èµ„å»ºè®® + é£é™©æç¤º (2å¥)

ä¿æŒä¸“ä¸šå®¢è§‚ï¼Œæ€»å…±ä¸è¶…è¿‡150å­—ã€‚"""
        
        response = self.client.chat.completions.create(
            model="deepseek-chat",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3,
            max_tokens=300,
        )
        
        return response.choices[0].message.content


# ============================================================
# ä¸»ç®¡é“
# ============================================================

class FinanceChatAgent:
    """
    é‡‘èå¯¹è¯ Agent
    
    å®Œæ•´æµç¨‹:
    ç”¨æˆ·è¾“å…¥ â†’ NLPè§£æ â†’ æ•°æ®è·å– â†’ ç‰¹å¾åˆ†æ â†’ é¢„æµ‹ â†’ æŠ¥å‘Šç”Ÿæˆ
    """
    
    def __init__(self, api_key: str = None):
        self.api_key = api_key or os.environ.get("DEEPSEEK_API_KEY")
        if not self.api_key:
            raise ValueError("è¯·è®¾ç½® DEEPSEEK_API_KEY")
        
        self.nlp = NLPAgent(self.api_key)
        self.reporter = ReportGenerator(self.api_key)
    
    def chat(self, user_input: str, model: str = "prophet", verbose: bool = True) -> Dict[str, Any]:
        """
        å¯¹è¯æ¥å£
        
        Args:
            user_input: ç”¨æˆ·è‡ªç„¶è¯­è¨€è¾“å…¥
            model: é¢„æµ‹æ¨¡å‹ï¼Œå¯é€‰ "prophet" æˆ– "xgboost"ï¼Œé»˜è®¤ä¸º "prophet"
            verbose: æ˜¯å¦æ‰“å°è¿‡ç¨‹
            
        Returns:
            åŒ…å«é¢„æµ‹ç»“æœå’Œåˆ†ææŠ¥å‘Šçš„å­—å…¸
        """
        if verbose:
            print("="*60)
            print(f"ğŸ“ ç”¨æˆ·: {user_input}")
            print("="*60)
        
        # Step 1: è§£æç”¨æˆ·è¾“å…¥
        if verbose:
            print("\nğŸ¤– Step 1: è§£æéœ€æ±‚...")
        
        parsed = self.nlp.parse(user_input)
        data_config = parsed["data_config"]
        analysis_config = parsed["analysis_config"]
        
        if verbose:
            print(f"   â†’ æ•°æ®æº: {data_config['api_function']}")
            print(f"   â†’ å‚æ•°: {data_config['params']}")
            print(f"   â†’ é¢„æµ‹: {analysis_config['forecast_horizon']} å¤©")
        
        # Step 2: è·å–æ•°æ®
        if verbose:
            print("\nğŸ“Š Step 2: è·å–æ•°æ®...")
        
        raw_df = DataFetcher.fetch(data_config)
        df = DataFetcher.prepare(raw_df, data_config)
        
        # Step 3: ç‰¹å¾åˆ†æ
        if verbose:
            print("\nğŸ“ˆ Step 3: åˆ†æç‰¹å¾...")
        
        features = TimeSeriesAnalyzer.analyze_features(df)
        
        if verbose:
            print(f"   â†’ è¶‹åŠ¿: {features['trend']}, æ³¢åŠ¨: {features['volatility']}")
            print(f"   â†’ æœ€æ–°ä»·: {features['latest']}")
        
        # Step 4: é¢„æµ‹
        if verbose:
            print("\nğŸ”® Step 4: æ‰§è¡Œé¢„æµ‹...")
        
        horizon = analysis_config.get("forecast_horizon", 30)
        # ä½¿ç”¨ä¼ å…¥çš„ model å‚æ•°ï¼Œè¦†ç›– NLP Agent è¿”å›çš„æ¨¡å‹é€‰æ‹©
        model_name = model.lower() if model else analysis_config.get("model", "prophet").lower()
        
        # éªŒè¯æ¨¡å‹åç§°
        if model_name not in ["prophet", "xgboost"]:
            raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹: {model_name}ã€‚æ”¯æŒ: 'prophet', 'xgboost'")
        
        if model_name == "prophet":
            forecast_result = TimeSeriesAnalyzer.forecast_prophet(df, horizon)
        else:  # xgboost
            forecast_result = TimeSeriesAnalyzer.forecast_xgboost(df, horizon)
        
        if verbose:
            print(f"   â†’ æ¨¡å‹: {forecast_result['model']}")
            metrics_str = ", ".join([f"{k.upper()}: {v}" for k, v in forecast_result['metrics'].items()])
            print(f"   â†’ æŒ‡æ ‡: {metrics_str}")
        
        # Step 5: ç”ŸæˆæŠ¥å‘Š
        if verbose:
            print("\nğŸ“‹ Step 5: ç”ŸæˆæŠ¥å‘Š...")
        
        user_question = analysis_config.get("user_question", user_input)
        report = self.reporter.generate(user_question, features, forecast_result)
        
        # ç»“æœ
        result = {
            "config": {
                "data": data_config,
                "analysis": analysis_config
            },
            "data": {
                "raw_shape": raw_df.shape,
                "prepared_shape": df.shape,
                "df": df,  # æ ‡å‡†åŒ–åçš„æ•°æ®
            },
            "features": features,
            "forecast": forecast_result["forecast"],
            "metrics": forecast_result["metrics"],
            "report": report,
        }
        
        if verbose:
            print("\n" + "="*60)
            print("ğŸ’¡ åˆ†ææŠ¥å‘Š")
            print("="*60)
            print(report)
            print("="*60)
        
        return result
    
    def plot(self, result: Dict[str, Any], title: str = None):
        """ç»˜åˆ¶é¢„æµ‹å›¾"""
        import matplotlib.pyplot as plt
        
        df = result["data"]["df"]
        forecast = result["forecast"]
        
        fig, ax = plt.subplots(figsize=(12, 5))
        
        # å†å²
        ax.plot(df["ds"], df["y"], label="å†å²æ•°æ®", color="blue", lw=1.5)
        
        # é¢„æµ‹
        dates = pd.to_datetime([f["date"] for f in forecast])
        values = [f["value"] for f in forecast]
        lower = [f.get("lower") for f in forecast]
        upper = [f.get("upper") for f in forecast]
        
        ax.plot(dates, values, label="é¢„æµ‹", color="red", lw=2, ls="--")
        # åªæœ‰å½“ç½®ä¿¡åŒºé—´å­˜åœ¨æ—¶æ‰ç»˜åˆ¶
        if all(l is not None and u is not None for l, u in zip(lower, upper)):
            ax.fill_between(dates, lower, upper, alpha=0.2, color="red")
        
        ax.set_title(title or "æ—¶åºé¢„æµ‹")
        ax.legend()
        ax.grid(True, alpha=0.3)
        plt.tight_layout()
        plt.show()
        
        return fig


# ============================================================
# ä¾¿æ·å‡½æ•°
# ============================================================

def chat(query: str, model: str = "prophet", api_key: str = None) -> Dict[str, Any]:
    """
    å¿«é€Ÿå¯¹è¯æ¥å£
    
    Args:
        query: ç”¨æˆ·è‡ªç„¶è¯­è¨€è¾“å…¥
        model: é¢„æµ‹æ¨¡å‹ï¼Œå¯é€‰ "prophet" æˆ– "xgboost"ï¼Œé»˜è®¤ä¸º "prophet"
        api_key: DeepSeek API Keyï¼Œå¦‚æœä¸æä¾›åˆ™ä»ç¯å¢ƒå˜é‡è¯»å–
    
    Example:
        result = chat("åˆ†æå¹³å®‰é“¶è¡Œè¿‘ä¸€å¹´èµ°åŠ¿ï¼Œé¢„æµ‹æœªæ¥30å¤©", model="xgboost")
        print(result["report"])
    """
    agent = FinanceChatAgent(api_key)
    return agent.chat(query, model=model)


# ============================================================
# CLI
# ============================================================

if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1:
        query = " ".join(sys.argv[1:])
    else:
        query = input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜: ")
    
    result = chat(query)
    
    print("\né¢„æµ‹å€¼ (å‰10å¤©):")
    for f in result["forecast"][:10]:
        print(f"  {f['date']}: {f['value']:.2f}")